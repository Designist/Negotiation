{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive seq2seq\n",
    "Applying our trained encoder-decoder model so that it can produce and respond to dialogue in context. We will need to load the model, seq2seq_baseline.ckpt, which was trained on the NLP cluster with 2500 iterations and batch size of 1028."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import random\n",
    "import json\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/models/\")\n",
    "sys.path.append('../src/models/agents/')\n",
    "sys.path.append('../src/data/')\n",
    "from agent import Agent\n",
    "from parse import FBParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set global variables\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations = 3\n",
    "learning_rate = 0.1\n",
    "max_input_length = 6 # length of goals list\n",
    "max_output_length = 20\n",
    "unk_threshold = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize parser and agent\n",
    "Using the Agent() class which subclasses the basic TfEncoderDecoder for dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 502\n"
     ]
    }
   ],
   "source": [
    "parser = FBParser(unk_threshold=unk_threshold,\n",
    "                  input_directory=\"../data/raw/\",\n",
    "                  output_directory=\"../data/processed/\")\n",
    "print(\"Vocab size: {}\".format(parser.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(vocab=parser.vocab,\n",
    "              max_iter=train_iterations,\n",
    "              eta=learning_rate,\n",
    "              max_input_length=max_input_length,\n",
    "              max_output_length=max_output_length,\n",
    "              hidden_dim=64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "with open(\"../data/processed/train.txt\", \"r\") as train_file:\n",
    "    for line in train_file:\n",
    "        train_example = json.loads(line)\n",
    "        train_data.append((\n",
    "            train_example[\"input\"],\n",
    "            train_example[\"output\"][0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = zip(*train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration 2: loss: 51.83759260177612"
     ]
    }
   ],
   "source": [
    "agent.fit(X, y, save_path=\"../models/seq2seq\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the saved model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "newAgent = Agent(vocab=parser.vocab,\n",
    "              max_iter=train_iterations,\n",
    "              eta=learning_rate,\n",
    "              max_input_length=max_input_length,\n",
    "              max_output_length=max_output_length,\n",
    "              hidden_dim=64)\n",
    "newAgent.sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=False))\n",
    "newAgent.build_graph()\n",
    "newAgent.sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver = tf.train.import_meta_graph('../models/seq2seq.meta')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/seq2seq\n"
     ]
    }
   ],
   "source": [
    "saver.restore(newAgent.sess, '../models/seq2seq')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print elements of the graph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['encoder_inputs',\n",
       " 'encoder_lengths',\n",
       " 'decoder_inputs',\n",
       " 'decoder_targets',\n",
       " 'decoder_lengths',\n",
       " 'EmbedSequence/embeddings/Initializer/random_uniform/shape',\n",
       " 'EmbedSequence/embeddings/Initializer/random_uniform/min',\n",
       " 'EmbedSequence/embeddings/Initializer/random_uniform/max',\n",
       " 'EmbedSequence/embeddings/Initializer/random_uniform/RandomUniform',\n",
       " 'EmbedSequence/embeddings/Initializer/random_uniform/sub']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[n.name for n in tf.get_default_graph().as_graph_def().node]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data prediction\n",
    "Make sure the saved model works correctly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(\"../data/processed/test.txt\", \"r\") as test_file:\n",
    "    for line in test_file:\n",
    "        test_example = json.loads(line)\n",
    "        test_data.append((\n",
    "            test_example[\"input\"],\n",
    "            test_example[\"output\"][0].split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get first twenty examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = zip(*test_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by : : : : : : was was was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by : : : : : : was was was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by see : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "less was was was was was was was was was was was at was was was was at was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n",
      "by by by by : : : : : : : was was was was was was was was was\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "logits = newAgent.predict(X_test)\n",
    "print('\\nPredictions:\\n')\n",
    "for string in newAgent.output(logits, padding=\" \"):\n",
    "    print(string)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
