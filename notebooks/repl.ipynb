{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interactive seq2seq\n",
    "Applying our trained encoder-decoder model so that it can produce and respond to dialogue in context. We will need to load the model, seq2seq500embed, which was trained on the NLP cluster with 500 iterations and batch size of 1028."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "import random\n",
    "import json\n",
    "from tensorflow.python.layers.core import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../src/models/\")\n",
    "sys.path.append('../src/models/agents/')\n",
    "sys.path.append('../src/data/')\n",
    "from agent import Agent\n",
    "from parse import FBParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iterations = 3\n",
    "learning_rate = 0.1\n",
    "max_input_length = 6 # TODO: change this\n",
    "max_output_length = 20\n",
    "unk_threshold = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization and loading\n",
    "Need to initialize FBParser and Agent():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 502\n"
     ]
    }
   ],
   "source": [
    "parser = FBParser(unk_threshold=unk_threshold,\n",
    "                  input_directory=\"../data/raw/\",\n",
    "                  output_directory=\"../data/processed/\")\n",
    "print(\"Vocab size: {}\".format(parser.vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = Agent(vocab=parser.vocab,\n",
    "              max_iter=train_iterations,\n",
    "              eta=learning_rate,\n",
    "              max_input_length=max_input_length,\n",
    "              max_output_length=max_output_length,\n",
    "              hidden_dim=64)\n",
    "agent.sess = tf.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/seq2seq300embed\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.import_meta_graph('../models/seq2seq300embed.meta')\n",
    "saver.restore(agent.sess, '../models/seq2seq300embed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = []\n",
    "with open(\"../data/processed/test.txt\", \"r\") as test_file:\n",
    "    for line in test_file:\n",
    "        test_example = json.loads(line)\n",
    "        test_data.append((\n",
    "            test_example[\"input\"],\n",
    "            test_example[\"output\"][0].split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test, y_test = zip(*test_data[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = X_test\n",
    "X = np.asarray(list(X))\n",
    "x_lengths = [len(seq) for seq in X] # len(seq) == 6\n",
    "num_examples = len(X)\n",
    "length = 6\n",
    "\n",
    "# Resize X and x_lengths to match the size of inference_logits:\n",
    "X.resize((agent.batch_size, length))\n",
    "x_lengths = np.asarray(x_lengths)\n",
    "x_lengths.resize(agent.batch_size)\n",
    "\n",
    "graph = tf.get_default_graph()\n",
    "answer_logits = agent.sess.run(graph.get_tensor_by_name(\"inference_logits:0\"), {\n",
    "    graph.get_tensor_by_name(\"encoder_inputs:0\"): X, \n",
    "    graph.get_tensor_by_name(\"encoder_lengths:0\"): x_lengths})[:num_examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predictions:\n",
      "\n",
      "[2, 2, 3, 2, 1, 0]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[2, 0, 3, 1, 1, 7]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 2, 3, 3, 1]\n",
      "YOU: i can have the hat and the ball <eos> THEM: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 10, 2, 0, 3, 0]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 1, 5, 4, 1]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 9, 1, 1, 4, 0]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 1, 3, 3, 2]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 1, 0, 3, 3]\n",
      "YOU: i can have the hat and the ball <eos> THEM: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[2, 2, 3, 2, 2, 0]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[2, 0, 3, 2, 2, 2]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 1, 6, 3, 1]\n",
      "YOU: i can have the hat and the ball <eos> THEM: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 8, 1, 2, 3, 0]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[3, 1, 1, 1, 2, 3]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[3, 0, 1, 2, 2, 4]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[3, 2, 1, 2, 2, 1]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[3, 0, 1, 8, 2, 1]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[2, 3, 2, 1, 1, 2]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[2, 2, 2, 0, 1, 6]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 4, 0, 1, 9]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n",
      "[1, 1, 4, 1, 1, 5]\n",
      "YOU: i can have the hat and the ball <eos> YOU: ok <eos> YOU: deal <eos> YOU: <selection>\n"
     ]
    }
   ],
   "source": [
    "print('\\nPredictions:\\n')\n",
    "output = agent.output(answer_logits, padding=\" \")\n",
    "for i in range(len(output)):\n",
    "    print(X_test[i])\n",
    "    print(output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_string(string):\n",
    "    tokens = string.strip().split()\n",
    "    for i in range(len(tokens)):\n",
    "        if tokens[i] in agent.vocab:\n",
    "            tokens[i] = agent.vocab.index(tokens[i])\n",
    "        else:\n",
    "            tokens[i] = agent.vocab.index(\"$UNK\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [1, 0, 1, 5, 1, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reply = tokenize_string(\"<eos> THEM: hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given a single example X:\n",
    "def predict(X):\n",
    "    length = len(X)\n",
    "    X = [X]\n",
    "    X = np.asarray(list(X))\n",
    "    x_lengths = [len(seq) for seq in X] # len(seq) == 6\n",
    "    print(length)\n",
    "    print(x_lengths)\n",
    "    \n",
    "\n",
    "    # Resize X and x_lengths to match the size of inference_logits:\n",
    "    X.resize((agent.batch_size, length))\n",
    "    x_lengths = np.asarray(x_lengths)\n",
    "    x_lengths.resize(agent.batch_size)\n",
    "\n",
    "    graph = tf.get_default_graph()\n",
    "    answer_logits = agent.sess.run(graph.get_tensor_by_name(\"inference_logits:0\"), {\n",
    "        graph.get_tensor_by_name(\"encoder_inputs:0\"): X, \n",
    "        graph.get_tensor_by_name(\"encoder_lengths:0\"): x_lengths})\n",
    "    output = agent.output(answer_logits, padding=\" \")\n",
    "    return output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "[9]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'YOU: i can have the book and the ball <eos> YOU: ok <eos> THEM: deal <eos> THEM: ok deal <eos>'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_string = X + reply\n",
    "predict(new_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Found the issue: decoding_inference includes start_tokens, which come in between the encoder_inputs and the model output. Perhaps replace them with <eos\\> or something like that."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
